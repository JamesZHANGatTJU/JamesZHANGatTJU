# Ju Zhang

School of Computer Science and Technology, Tianjin University

No.135, Yaguan Road, Jinnan District, Tianjin, P. R. China, 300350

juzhang@tju.edu.cn

## EDUCATION

**Tianjin University**, Tianjin, China
- Ph.D. in Computer Application Technology (Sep 2015 - Present)
    - Thesis: An MRI-based Study on Male and Female Individual Vocal Characteristics
    - Adviser: Prof. **Kiyoshi Honda** and **Jianguo Wei**
    - Focus: Speech production, articulatory phonetics, speech synthesis
    
- M.E. in Computer Science and Technology (Sep 2012 - Jun 2015)
    - Thesis: AVSR integrating 3D Lip Information obtained from the Kinect
    - Adviser: Prof. **Jianrong Wang**
    - Focus: Robust Speech Recognition, lipreading
    
**Tianjin Polytechnic University**, Tianjin, China
- Bachelors degrees with a double major:
    - B.E. in Software Engineering, **GPA ranks 7/198**
    - B.A. in English, **GPA ranks 1/79**

## RESEARCH EXPERIENCE

### Tianjin Key Lab of Cognitive Computing and Application, Tianjin University

**Hypopharynx Morphological Characteristics in Gender Difference (Dec 2017 - Aug 2018)**

- Intro: This study explored the morphological commonalities and differences of the hypopharyngeal cavities between
the male and female subjects based on magnetic resonance imaging observations.
- This study provided data for better understanding the causal factors for male-female speaker individualities.

**Tooth Visualization in Vowel Production Magnetic Resonance Images (Dec 2016 - Dec 2017)**

- Intro: This study proposed a new method to visualize the teeth in vowel production magnetic resonance images for
the application of 3D vocal tract modeling.
- The proposed method solved the MRI-specific problem of the lack of tooth images and contributes to accurate 3D
vocal tract measurement and reconstruction.

**Acoustic Analysis of the Vocal Tract Open End Effect (Mar 2015 - Dec 2015)**

- Intro: This study investigated acoustic effect of the vocal tract open end to examine whether the open-end correction
coefficient known to date is adequate for modeling the vocal tracts with a wide-open mouth.
- This work suggested that the coefficient for correction needs to be adjusted in models to reflect the geometry of the
lip end of the vocal tract.

**Coordination of Lip and Tongue in Natural Speech (Mar 2015 - Sep 2016)**

- Intro: This study analyzed the the lip opening, spreading, narrowing and protrusion, and then compared the changes
in those components with tongue surface deformation with real visual data, which captured by Microsoft Kinect for
Windows and Terason T3000 ultrasound auto view system.
- This work revealed a certain underlying mechanism of articulatory co-variation that can simplify the coordination of
motor activities across organs during speech production.

**The Study of Formulating a Concept for the Pharynx Physiological Model (Nov 2014 - Feb 2015)**

- Intro: This work analyzed the expansion and contraction of the pharyngeal wall during the word utterance from the
dynamic images obtained by MRI imaging technique.
- This work explored the mechanism of pharyngeal wall movement during the word utterance.

**Automatic Speech Recognition using Kinect Multi-Sensors for Robot NAO (Nov 2014 - Mar 2015)**

- Intro: This work proposed a multi-modal information fusion-based audio-visual speech recognition system.
- Aiming to improve the speech recognition performance of robot NAO under noisy environments.

**Audio-Visual Speech Recognition Integrating 3D Lip Information (Sep 2013 - Jul 2014)**

- Intro: This work proposed an audio-visual speech recognition system integrating 3D lip information obtained from
Microsoft Kinect for Windows version 1.
- The proposed framework is superior to traditional automatic speech recognition and audio-visual speech recognition
system in acoustic noise environments.

**Lipreading using Profile Lips Rebuilt by 3D Data from the Kinect (Apr 2014 - Jun 2014)**

- Intro: This work proposed a lipreading system with combination of profile lips rebuilt by the 3D data captured by
Microsoft Kinect version 1.
- Aiming to improve the performance of the traditional frontal lipreading.

**Speech Recognition with Single-Channel for Robot NAO (Oct 2012 - Jun 2013)**

- Intro: This work proposed an automatic speech recognition framework for de-noising the robot NAO ego motor noises.
- The proposed framework significantly reduce the effect of ego-noises and thereby enhance the robustness of automatic
speech recognition.

**Sound Source Localization based on Microphone Uniform Linear Array (Dec 2011 - Jun 2012)**

- Intro: This work improved the traditional multiple signal classification algorithm to increase the localization
performance by our designed weighted average filters.

## PUBLICATIONS

### JOURNALS

[1] **J. Zhang**, K. Honda, J. Wei* and T. Kitamura, ”Morphological characteristics of male and female hypopharynx: An MRI-based study,” _Journal of the Acoustical Society of America_, vol. 145, no. 2, pp. 734-748, 2018. **(Top journal in the field of speech production, CCF-B)**

[2] **J. Zhang**, K. Honda, and J. Wei*, ”Tooth visualization in vowel production MR images for three-dimensional vocal tract modeling,” _Speech Communication_, vol. 96, pp. 37-48, 2018. **(Top journal in the field of speech production, CCF-B)**

[3] **K. Honda and J. Zhang**, ”Articulatory modeling of human and non-human vocal production,” _Journal of the Acoustical Society of America_, vol. 143, no. 3, pp. 1787-1787, 2018. **(Invited talk in 175th Meeting of the Acoustical Society of America in Minneapolis)**

[4] J. Wang, Y. Gao, **J. Zhang**, J. Wei, and J. Dang, ”Automatic speech recognition by a Kinect sensor for a robot under ego noises,” _Journal of Tsinghua University (Science and Technology)_, vol. 57, no. 9, pp. 921-925, 2017. **(EI)**

)
[5] Y. Chen*, **J. Zhang**, J. Sieg, and Y. Chen, ”Is [γ] in Mandarin a transitional vowel? –Evidence from tongue movement by Ultrasound imaging,” _Journal of Chinese Linguistics (JCL)_, 2017. (Accepted) **(SSCI)**

[6] W. Lu, **J. Zhang**, X. Zhao, J. Wang*, and J. Dang, ”Multimodal sensory fusion for soccer robot self-localization based on long short-term memory recurrent neural network,” _Journal of Ambient Intelligence and Humanized Computing (AIHC)_, vol. 8, no. 6, pp. 885-893, 2017. **(SCI-4)**

[7] **J. Wang, J. Zhang**, W. Lu, J. Wei*, and J. Dang, ”Automatic speech recognition with robot noise,” _Journal of Tsinghua University (Science and Technology)_, vol. 57, no. 2, pp. 153-157, 2017. **(EI)**

[8] Y. Chen*, **J. Zhang**, H. Wang, J. Zhang, Y. Chen, H. Lin, and J. Dang, ”The MFCC vowel space of [γ] in grammatical and lexical word in standard Chinese,” _Chinese Lexical Semantics_, pp. 687-699, 2016. **(EI)**

[9] **J. Wang, J. Zhang**, K. Honda, J. Wei*, and J. Dang, ”Audio-visual speech recognition integrating 3D lip information obtained from the Kinect,” _Multimedia Systems_, vol. 22, no. 3, pp. 315-323, 2016. **(SCI-3, CCF-C)**

[10] J. Wang, Y. Gao, **J. Zhang**, J, Wei*, and J. Dang, ”Lipreading using profile lips rebuilt by 3D data from the Kinect,” _Journal of Computational Information Systems_, vol. 11, no. 7, pp. 2429-2438, 2015. **(EI)**

### CONFERENCES

[1] J. Wei, F. Yang, **J. Zhang**, R. Yu, M. Yu and J. Wang, ”Three-dimensional joint geometric-physiologic feature for lip-reading,” in _Proceedings of the International Conference on Tools with Artificial Intelligence (ICTAI)_, 2018, pp. 1007-1012. **(EI, CCF-C)**

[2] J. Wang, L. Wang, **J. Zhang**, J. Wei, M. Yu, and R. Yu, ”A large-scale depth-based multimodal audio-visual corpus in Mandarin,” in _Proceedings of the International Conference on High Performance Computing and Communications (HPCC)_, 2018, pp. 881-885. **(EI, CCF-C)**

[3] Z. Zhang, J. Wei, **J. Zhang*** and K. Honda, ”Acoustic analysis of the open-end effect using solid vocal tract models constructed from MRI data during vowel production,” in _Proceedings of the International Conference on Information Science and Control Engineering (ICISCE)_, 2018, pp. 1062-1066. **(EI)**

[4] X. Feng, W. Lu, **J. Zhang**, Y. Chi, and K. Honda*, ”Relative tongue size as an index to predict individual articulatory difference,” in _Proceedings of the Biennial Asia Pacific Conference on Speech, Language and Hearing (APCSLH)_, 2017, pp. 1-1.

[5] **Y. Chen+, J. Zhang+**, and J. Dang, ”How the speeds of articulator movement change in producing diphthongs? —–Evidence from acceleration calculation,” in _Proceedings of the International Seminar on Speech Production (ISSP)_, 2017, pp. 1-4. **(EI)**

[6] Y. Chen*, **J. Zhang**, F. Chen, Y. Chen, H. Lin, J. Wei, and J. Dang, ”A new method of acceleration measurement for observing tongue movement in Ultrasound image during speech production,” in _Proceedings of the Asia-Pacific Signal and Information Processing Association Summit and Conference (APSIPA)_, 2016, pp. 1-4. **(EI, ISTP)**

[7] Y. Chen*, Y. Chen, J. Zhang, **J. Zhang**, H. Lin, J. Wei, and J. Dang, ”Mandarin citation tone patterns of prelingual Chinese deaf adults,” in _Proceedings of the Asia-Pacific Signal and Information Processing Association Summit and Conference (APSIPA)_, 2016, pp. 1-4. **(EI, ISTP)**

[8] **J. Zhang**, K. Honda, J. Wei*, J. Wang and J. Dang, ”Spatial co-variation of lip and tongue at strong and weak syllables,” in _Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)_, 2016, pp. 1-5. **(EI)**

[9] C. Zhang, K. Honda, **J. Zhang**, and J. Wei*, ”Contributions of the piriform fossa of female speakers to vowel spectra,” in _Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)_, 2016, pp. 1-5. **(EI) (Best Student Paper Nomination Rewards)**

[10] J. Li, K. Honda, **J. Zhang**, and J. Wei*, ”Individual difference and acoustic effect of female laryngeal cavities,” in _Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)_, 2016, pp. 1-5. **(EI)**

[11] Y. Chen*, **J. Zhang**, H. Wang, J. Zhang, Y. Chen, H. Lin, and J. Dang, ”The MFCC vowel space of [γ] in grammatical and lexical word in standard Chinese,” in _Proceedings of the Workshop on Chinese Lexical Semantics (CLSW)_, 2016, pp. 1-6. **(EI)**

[12] J. Wang, Y. Yang, J. Wei*, and **J. Zhang**, ”Continuous ultrasound based tongue movement video synthesis from speech,” in _Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP)_, 2016, pp. 1716-1720. **(Top conference in the field of speech signal processing, EI, ISTP, CCF-B)**

[13] **J. Wang, J. Zhang**, J. Wei*, W. Lu, and J. Dang, ”Automatic speech recognition under robot ego noises,” in _Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)_, 2014, pp. 377-377. **(EI, ISTP)**

[14] **J. Wang, J. Zhang**, S. Hyon, and J. Wei*, ”Sound source localization based on microphone uniform linear array,” in _Proceedings of the International Conference on Material and Manufacturing Technology (ICMMT)_, 2013, pp. 634-639. **(EI)**

## AWARDS & SCHOLARSHIPS

- Kiyoshi Honda Speech Science Scholarship, First Prize (2014 - 2016)
- 2016 ISCSLP Best Student Paper Nomination Rewards (2016)
- Academic Scholarship, Tianjin University, First Prize (2012, 2015)
- School Merit Student Scholarship, Tianjin University (2013)
- Outstanding Student Scholarship, Tianjin Polytechnic University (2009 - 2011)
- Presidential Scholarship, Tianjin Polytechnic University, First Prize (2011)

## ACADEMIC ACTIVITIES

- Member of Acoustical Society of America (ASA)
- Member of Association for Computing Machinery (ACM)
- Member of China Computer Federation (CCF)
- Guest Reviewer, APSIPA
